{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Notebook1: Introduction_to_CUDA_and_PyCUDA.ipynb","provenance":[],"collapsed_sections":["p2JZt1GL5D6W","Rakk0eUMHRR7","jkHN6o9I-SZK","JU2DYoiMXP9J","ZHd1cmag_Wbx","0AiqHKSh_ZdU","nGxPkOSsARmP","UHBgezKxBdnE","1Kd13_mbB8eb","rhIg22xHYJU9","Si7HbO0gbjTQ","oGGhkm8xY-cr","8d69Myu1ksP-","3y8KJLfTmTGo"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"p2JZt1GL5D6W"},"source":["# Introduction to CUDA and PyCUDA\n","\n","PyCUDA gives you easy, Pythonic access to Nvidia’s CUDA parallel computation API. \n","\n","*   Abstractions make CUDA programming easier\n","*   Full power of CUDA API if needed\n","*   Automatic error checking and cleanup\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Rakk0eUMHRR7"},"source":["## Initialization\n","A few modules have to be loaded to initialize communication to the GPU:\n","\n","*   import pycuda.driver as cuda\n","*   import pycuda.autoinit\n","\n","The pycuda.driver module has methods that:\n","1. Allocate memory on the GPU (cuda.mem alloc())\n","2. Copy numpy arrays to the GPU (cuda.memcpy htod())\n","3. Execute kernels on the GPU described by CUDA code (see compiler.SourceModule)\n","4. Copy data from the GPU back to numpy arrays (cuda.memcpy dtoh())."]},{"cell_type":"code","metadata":{"id":"FA_YN7HlGRP5"},"source":["# Import PyCUDA and several modules associated with the PyCUDA\n","!pip install pycuda # install cuda\n","import pycuda\n","import pycuda.driver as cuda\n","cuda.init()\n","\n","import pycuda.autoinit\n","from pycuda.compiler import SourceModule\n","import pycuda.gpuarray as gpuarray\n","from pycuda.curandom import rand as curand\n","from pycuda.elementwise import ElementwiseKernel\n","\n","import numpy as np\n","import numpy.linalg as la"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u7uA7OVrTLIl"},"source":["CUDA device query"]},{"cell_type":"code","metadata":{"id":"TtnIrmDaQmm9"},"source":["print('CUDA device query (PyCUDA version) \\n')\n","print('Detected {} CUDA Capable device(s) \\n'.format(cuda.Device.count()))\n","for i in range(cuda.Device.count()):\n","    \n","    gpu_device = cuda.Device(i)\n","    print('Device {}: {}'.format( i, gpu_device.name() ) )\n","    compute_capability = float( '%d.%d' % gpu_device.compute_capability() )\n","    print('\\t Compute Capability: {}'.format(compute_capability))\n","    print('\\t Total Memory: {} megabytes'.format(gpu_device.total_memory()//(1024**2)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jkHN6o9I-SZK"},"source":["# Writing the kernel in CUDA"]},{"cell_type":"markdown","metadata":{"id":"JU2DYoiMXP9J"},"source":["## Doubling the value of elements in an array\n","\n","Here, we will take an array and double the element of it on the GPU."]},{"cell_type":"markdown","metadata":{"id":"ZHd1cmag_Wbx"},"source":["### Step1: Getting started"]},{"cell_type":"code","metadata":{"id":"-g92eSBn5FlC"},"source":["# Declare the array as follows:\n","np.random.seed(1729)\n","a = np.random.randn(4,4).astype(np.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0AiqHKSh_ZdU"},"source":["### Step 2: Transferring Data to the GPU\n","\n","The next step in most programs is to transfer data onto the device. In PyCuda, you will mostly transfer data from numpy arrays on the host."]},{"cell_type":"code","metadata":{"id":"92L9E7WkJhsy"},"source":["# firstly, we need to allocate memory on the device\n","a_gpu = cuda.mem_alloc(a.nbytes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1xaAt_NJjSb"},"source":["# we need to transfer the data to the GPU\n","cuda.memcpy_htod(a_gpu, a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nGxPkOSsARmP"},"source":["### Step 3: Executing a Kernel\n","\n","For this tutorial, we will write code to double each entry in a_gpu. To this end, we write the corresponding CUDA C code, and feed it into the constructor of a [pycuda.compiler.SourceModule](https://documen.tician.de/pycuda/driver.html#pycuda.compiler.SourceModule):"]},{"cell_type":"code","metadata":{"id":"bSAkS6e2Jk38"},"source":["# Double each entry in the variable a_gpu\n","mod = SourceModule(\"\"\"\n","  __global__ void twice(float *a)\n","  {\n","    int idx = threadIdx.x + threadIdx.y*4;\n","    a[idx] *= 2;\n","  }\n","  \"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4NQf5XcAsEI"},"source":["If there aren’t any errors, the code is now compiled and loaded onto the device. We find a reference to our [pycuda.driver.Function](https://documen.tician.de/pycuda/driver.html#pycuda.driver.Function) and call it, specifying a_gpu as the argument, and a block size of 4x4:"]},{"cell_type":"code","metadata":{"id":"fBQ0blkNJnIg"},"source":["func = mod.get_function(\"twice\")\n","func(a_gpu, block=(4,4,1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"whSsByHBUaiY"},"source":["Finally, we fetch the data back from the GPU and display it, together with the original a:"]},{"cell_type":"code","metadata":{"id":"_ef82NDPJqWV"},"source":["a_doubled = np.empty_like(a)\n","cuda.memcpy_dtoh(a_doubled, a_gpu)\n","\n","print(\"a\",a)\n","print(\"\\nDoubled value\",a_doubled)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHBgezKxBdnE"},"source":["### Abstracting Away the Complications\n","\n","Using a [pycuda.gpuarray.GPUArray](https://documen.tician.de/pycuda/array.html#pycuda.gpuarray.GPUArray), the same effect can be achieved with much less writing:"]},{"cell_type":"code","metadata":{"id":"24Wk5V33eLUQ"},"source":["# implementing with gpu_array\n","a_gpu = gpuarray.to_gpu(a)\n","a_doubled = (2*a_gpu).get()\n","print(\"a\",a)\n","print(\"\\nDoubled value\",a_doubled)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Kd13_mbB8eb"},"source":["### Shortcuts for Explicit Memory Copies\n","\n","The [pycuda.driver.In](https://documen.tician.de/pycuda/driver.html#pycuda.driver.In), [pycuda.driver.Out](https://documen.tician.de/pycuda/driver.html#pycuda.driver.Out), and [pycuda.driver.InOut](https://documen.tician.de/pycuda/driver.html#pycuda.driver.InOut) argument handlers can simplify some of the memory transfers. For example, instead of creating a_gpu, if replacing a is fine, the following code can be used:"]},{"cell_type":"code","metadata":{"id":"f6-BYWwsniNR"},"source":["# implementing with InOut\n","func(cuda.InOut(a), block=(4, 4, 1))\n","print(\"a\",a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rhIg22xHYJU9"},"source":["##Addition of two 1D arrays\n","\n","Here, we will add two 1D arrays and execute it on GPU."]},{"cell_type":"code","metadata":{"id":"hHZsceK_Zlxr"},"source":["# declare arrays\n","m = np.random.randn(10).astype(np.float32)\n","n = np.random.randn(10).astype(np.float32)\n","\n","# execute the kernel\n","mod2_1D = SourceModule(\"\"\"\n","__global__ void sum2arr(float *sum, float *m, float *n)\n","{\n","  const int i = threadIdx.x;\n","  sum[i] = m[i] + n[i];\n","}\n","\"\"\")\n","\n","func = mod2_1D.get_function(\"sum2arr\")\n","\n","# handle memory transfer with 'Out()'\n","sum_1D = np.zeros_like(m)\n","func(cuda.Out(sum_1D),\n","     cuda.In(m), cuda.In(n),\n","     block=(10,1,1))\n","\n","# print result\n","print(\"m\",m)\n","print(\"\\nn\",n)\n","print(\"\\nsum\",sum_1D)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Si7HbO0gbjTQ"},"source":["## Addition of matrices\n","\n","Here, we will add two matrices and execute it on GPU."]},{"cell_type":"code","metadata":{"id":"kXx_p97mJs4Z"},"source":["# declare matrices\n","b = np.random.randn(4,4).astype(np.float32)\n","c = np.random.randn(4,4).astype(np.float32)\n","\n","# execute the kernel\n","mod2_2D = SourceModule(\"\"\"\n","  __global__ void add2(float *a, float *b)\n","  {\n","    int idx = threadIdx.x + threadIdx.y*4;\n","    a[idx] += b[idx];\n","  }\n","  \"\"\")\n","\n","func = mod2_2D.get_function(\"add2\")\n","\n","# transfer the data to the GPU\n","b_gpu = cuda.mem_alloc(b.nbytes)\n","c_gpu = cuda.mem_alloc(c.nbytes)\n","\n","cuda.memcpy_htod(b_gpu, b)\n","cuda.memcpy_htod(c_gpu, c)\n","\n","func(b_gpu,c_gpu, block=(4,4,1))\n","\n","sum_2D = np.empty_like(b)\n","cuda.memcpy_dtoh(sum_2D, b_gpu)\n","\n","# print result\n","print(\"b\",b)\n","print(\"\\nc\",c)\n","print(\"\\nsum\",sum_2D)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oGGhkm8xY-cr"},"source":["##Multiplication of matrices\n","\n","Here, we will multiple two matrices and execute it on GPU."]},{"cell_type":"code","metadata":{"id":"-dAKCn25Vggp"},"source":["# declare matrices\n","r = np.random.randn(10).astype(np.float32)\n","s = np.random.randn(10).astype(np.float32)\n","\n","# execute kernel\n","mod3 = SourceModule(\"\"\"\n","__global__ void multiply2arr(float *dest, float *r, float *s)\n","{\n","  const int i = threadIdx.x;\n","  dest[i] = r[i] * s[i];\n","}\n","\"\"\")\n","\n","func = mod3.get_function(\"multiply2arr\")\n","\n","product = np.zeros_like(r)\n","\n","# handle memory transfer\n","func(cuda.Out(product),\n","     cuda.In(r), cuda.In(s),\n","     block=(10,1,1))\n","\n","# print result\n","print(\"r\",r)\n","print(\"\\ns\",s)\n","print(\"\\nproduct\",product)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8d69Myu1ksP-"},"source":["## Linear combination of variables\n","\n","The functionality in the module [pycuda.elementwise](https://documen.tician.de/pycuda/array.html#module-pycuda.elementwise) contains tools to help generate kernels that evaluate multi-stage expressions on one or several operands in a single pass. Here's a usage example:"]},{"cell_type":"code","metadata":{"id":"zmqyWfJpjw7X"},"source":["# generate arrays of random numbers using curand()\n","n1_gpu = curand((10,))\n","n2_gpu = curand((10,))\n","\n","# generate a kernel that takes a number of scalar or vector arguments and performs the scalar operation on each entry of its arguments, if that argument is a vector.\n","linear_combination = ElementwiseKernel(\n","        \"float a, float *x, float b, float *y, float *z\",\n","        \"z[i] = my_f(a*x[i], b*y[i])\",\n","        \"linear_combination\",\n","        preamble=\"\"\"\n","        __device__ float my_f(float x, float y)\n","        { \n","          return sin(x*y);\n","        }\n","        \"\"\")\n","\n","# make a new, uninitialized GPUArray having the same properties as other_ary\n","c_gpu = gpuarray.empty_like(n1_gpu)\n","\n","# call the function\n","linear_combination(5, n1_gpu, 6, n2_gpu, c_gpu)\n","\n","# test for a particular condition\n","assert la.norm(c_gpu.get() - np.sin((5*n1_gpu*6*n2_gpu).get())) < 1e-5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3y8KJLfTmTGo"},"source":["## Numba and PyCUDA\n","\n","The module [pycuda.autoprimaryctx](https://documen.tician.de/pycuda/util.html#module-pycuda.autoprimaryctx) is similar to [pycuda.autoinit](https://documen.tician.de/pycuda/util.html#module-pycuda.autoinit), except that it retains the device primary context instead of creating a new context in [pycuda.tools.make_default_context()](https://documen.tician.de/pycuda/util.html#pycuda.tools.make_default_context). Notably, it also has device and context attributes."]},{"cell_type":"code","metadata":{"id":"UDtaDlzzmWWv"},"source":["from numba import cuda\n","\n","# Using autoprimaryctx instead of autoinit since Numba can only operate on a primary context\n","import pycuda.autoprimaryctx  \n","\n","# Creating a PyCUDA gpuarray\n","print(\"a\",a_gpu)\n","\n","# Numba kernel\n","@cuda.jit\n","def double(x):\n","    i, j = cuda.grid(2)\n","\n","    if i < x.shape[0] and j < x.shape[1]:\n","        x[i, j] *= 2\n","\n","# Calling the Numba kernel on the PyCUDA gpuarray, using the CUDA Array Interface transparently\n","double[(4, 4), (1, 1)](a_gpu)\n","print(\"Doubling values using numba: \",a_gpu)"],"execution_count":null,"outputs":[]}]}