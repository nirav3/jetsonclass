{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face and Eye Recognition\n",
    "Before we discuss redaction, lets cover the basics of identifying a face within an image.\n",
    "\n",
    "Within OpenCV-Python, we can use the cv2.rectangle method to draw a rectangle over an image. We need five parameters for this function: image, start_point, end_point, color, and thickness. \n",
    "\n",
    "We can get the start and end points by running a classier to identify the area that contains the face. The code block below uses the haarcascade classifier.  Images must be converted to grayscale before applying the classifier.  The end result is the detectmultiscale function returns an array that correspond to the coordinates for the rectangle that you will input in the opencv rectangle function.\n",
    "\n",
    "A similar pattern is performed to identify any other features such as the eyes which is done in the code block below. We draw the rectangles for the face and eye over the original image and display it in a widget. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecd2917944e4b8cb3adb15368747f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5777b895d1e943d1bf28f9462fe056b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/how-to-blur-faces-in-images-using-opencv-in-python/\n",
    "#https://docs.opencv.org/3.1.0/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0\n",
    "# Importing libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "# A function for plotting the images\n",
    "\n",
    "oimage_widget = ipywidgets.Image(format='jpeg')\n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "# Reading an image using OpenCV\n",
    "# OpenCV reads images by default in BGR format\n",
    "image = cv2.imread('lena_color.tif')\n",
    "\n",
    "# Converting BGR image into a RGB image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# plotting the original image\n",
    "oimage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "oimage_widget.value = bytes(cv2.imencode('.jpg', oimage)[1])\n",
    "display(oimage_widget)\n",
    "\n",
    "#need to ensure this matches the actual file locations!\n",
    "fpath='./cascades/haarcascade_frontalface_alt.xml'\n",
    "epath='./cascades/haarcascade_eye.xml'\n",
    "\n",
    "face_detect = cv2.CascadeClassifier(fpath)\n",
    "eye_detect = cv2.CascadeClassifier(epath)\n",
    "\n",
    "#returns an array that identifies the four points that contain the face\n",
    "faces = face_detect.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    eyes = eye_detect.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "       \n",
    "\n",
    "# Display the output\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "image_widget.value = bytes(cv2.imencode('.jpg', image)[1])\n",
    "display(image_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redact an image - CPU\n",
    "Now lets blur the are within the rectangle to redact the face using the OpenCV GaussianBlur function. We will not identify eyes in this code block, just the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3ded8e29ce4f25a4941bf0f773e7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 200 ms, sys: 28 ms, total: 228 ms\n",
      "Wall time: 426 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "# Reading an image using OpenCV\n",
    "image = cv2.imread('lena_color.tif')\n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "\n",
    "# Converting BGR image into a RGB image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fpath='./cascades/haarcascade_frontalface_alt.xml'\n",
    "\n",
    "face_detect = cv2.CascadeClassifier(fpath)\n",
    "\n",
    "faces = face_detect.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    roi = cv2.GaussianBlur(roi_color, (23, 23), 30)\n",
    "    # impose this blurred image on original image to get final image\n",
    "    image[y:y+roi.shape[0], x:x+roi.shape[1]] = roi\n",
    "\n",
    "# Display the output\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "image_widget.value = bytes(cv2.imencode('.jpg', image)[1])\n",
    "display(image_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redact an image -GPU\n",
    "Now lets use the GPU to run the classifier. \n",
    "In this code block, we upload the image to the GPU, run it against the CUDA version of the classifier, the download the array that contains the coodinates and the image to the CPU.  We must download the results to the CPU in order to draw the rectangle and display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f4222ddadf47a9831b40c5c08fc93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 192 ms, sys: 28 ms, total: 220 ms\n",
      "Wall time: 476 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "\n",
    "image = cv2.imread('lena_color.tif')\n",
    "\n",
    "# Converting BGR image into a RGB image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fpath='./cascades_cuda/haarcascade_frontalface_alt.xml'\n",
    "\n",
    "cuImage = cv2.cuda_GpuMat()\n",
    "\n",
    "cuImage.upload(image)\n",
    "\n",
    "gray = cv2.cuda.cvtColor(cuImage,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_detect = cv2.cuda_CascadeClassifier.create(fpath)\n",
    "\n",
    "faces = face_detect.detectMultiScale(gray).download()\n",
    "gray = gray.download()\n",
    "\n",
    "if faces is not None:\n",
    "    #print(faces[0])\n",
    "\n",
    "    #this must be done on CPU\n",
    "    for (x,y,w,h) in faces[0]:\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = image[y:y+h, x:x+w]\n",
    "        roi = cv2.GaussianBlur(roi_color, (23, 23), 30)\n",
    "        # impose this blurred image on original image to get final image\n",
    "        image[y:y+roi.shape[0], x:x+roi.shape[1]] = roi\n",
    "\n",
    "cuImage.upload(image)\n",
    "fimage = cv2.cuda.cvtColor(cuImage, cv2.COLOR_RGB2BGR)\n",
    "fimage = fimage.download()\n",
    "# Display the output\n",
    "\n",
    "image_widget.value = bytes(cv2.imencode('.jpg', fimage)[1])\n",
    "\n",
    "display(image_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
