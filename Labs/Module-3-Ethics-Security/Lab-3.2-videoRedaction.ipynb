{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a818f16",
   "metadata": {},
   "source": [
    "## Video Redaction CPU\n",
    "Here we are reading in a video file, identifying the face, drawing a rectangle around the face and blurring the area inside the rectangle\n",
    "For the ease of working with your Nano remotely within Jupyter-lab, we are reducing the size of the video and displaying it in a widget.\n",
    "\n",
    "We are using the magic %%time to view the overall run of the code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e416ac9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7652809300147d583f4e33e702b11d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 2.89 s, total: 1min 16s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#creative common video downloaded from https://www.youtube.com/watch?v=BLaf9_jHQyQ\n",
    "\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import base64\n",
    "import cv2\n",
    "\n",
    "vwidth = 640\n",
    "vheight = 480 \n",
    "\n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "\n",
    "display(image_widget)\n",
    "\n",
    "cap = cv2.VideoCapture('faceR.mp4')\n",
    "\n",
    "frames = []\n",
    "\n",
    "fpath='./cascades/haarcascade_frontalface_alt.xml'\n",
    "\n",
    "face_detect = cv2.CascadeClassifier(fpath)\n",
    "\n",
    "while(1):\n",
    "    try:\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        frame_resized = cv2.resize(frame,(int(vwidth),int(vheight)))\n",
    "        imgframe = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(imgframe, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = face_detect.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame_resized,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame_resized[y:y+h, x:x+w]\n",
    "            roi = cv2.GaussianBlur(roi_color, (23, 23), 30)\n",
    "            # impose this blurred image on original image to get final image\n",
    "            frame_resized[y:y+roi.shape[0], x:x+roi.shape[1]] = roi\n",
    "        image_widget.value = bytes(cv2.imencode('.jpg', frame_resized)[1])\n",
    "      \n",
    "    except Exception:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd6d82",
   "metadata": {},
   "source": [
    "## Video Redaction GPU\n",
    "Now lets use the GPU to performa the image classification.\n",
    "Did this code block run faster or slower than the previous code block?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bd5e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12c9d3a856149d0b7e95870d8e26d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 2.1 s, total: 12.3 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#creative common video from https://www.youtube.com/watch?v=BLaf9_jHQyQ\n",
    "\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import base64\n",
    "import cv2\n",
    "\n",
    "\n",
    "rimage_widget = ipywidgets.Image(format='jpeg')\n",
    "\n",
    "display(rimage_widget)\n",
    "\n",
    "cap = cv2.VideoCapture('faceR.mp4')\n",
    "\n",
    "frames = []\n",
    "\n",
    "fpath='./cascades_cuda/haarcascade_frontalface_alt.xml'\n",
    "\n",
    "cuImage = cv2.cuda_GpuMat()\n",
    "\n",
    "face_detect = cv2.cuda_CascadeClassifier.create(fpath)\n",
    "\n",
    "while(1):\n",
    "    try:\n",
    "        _, frame = cap.read()\n",
    "       \n",
    "        #fgmask = cv2.Canny(frame, 100, 100)\n",
    "        frame_resized = cv2.resize(frame,(int(vwidth),int(vheight)))\n",
    "        imgframe = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "        #gray = cv2.cvtColor(imgframe, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        cuImage.upload(imgframe)\n",
    "        gray = cv2.cuda.cvtColor(cuImage,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_detect.detectMultiScale(gray).download()\n",
    "        gray = gray.download()\n",
    "\n",
    "        #faces = face_detect.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces[0]:\n",
    "            cv2.rectangle(frame_resized,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame_resized[y:y+h, x:x+w]\n",
    "            roi = cv2.GaussianBlur(roi_color, (23, 23), 30)\n",
    "            # impose this blurred image on original image to get final image\n",
    "            frame_resized[y:y+roi.shape[0], x:x+roi.shape[1]] = roi\n",
    "        rimage_widget.value = bytes(cv2.imencode('.jpg', frame_resized)[1])\n",
    "      \n",
    "    except Exception:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d385e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Widget\n",
    "Widget.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ab8a744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
